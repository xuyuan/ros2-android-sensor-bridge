<!DOCTYPE html>
<html style="background-color: black; color: white;">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <title>WebXR Pose Data</title>
    <style>
      body, html {
        margin: 0;
        padding: 0;
        background-color: black;
        color: white;
        font-family: Arial, sans-serif;
        height: 100%;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
      }

      .container {
        background: rgba(30, 30, 30, 0.9);
        padding: 2rem;
        border-radius: 10px;
        box-shadow: 0 0 20px rgba(0, 0, 0, 0.5);
        max-width: 500px;
        width: 90%;
      }

      .title {
        text-align: center;
        margin-bottom: 2rem;
        font-size: 24px;
      }

      .sensor-select {
        position: static;
        background: none;
        padding: 0;
      }

      .sensor-select label {
        display: flex;
        align-items: center;
        padding: 1rem;
        margin: 0.5rem 0;
        background: rgba(50, 50, 50, 0.5);
        border-radius: 5px;
        cursor: pointer;
        transition: background 0.3s;
      }

      .sensor-select label:hover {
        background: rgba(70, 70, 70, 0.5);
      }

      .sensor-select input[type="checkbox"] {
        margin-right: 15px;
        transform: scale(1.5);
      }

      #xr-button {
        width: 100%;
        padding: 1rem;
        font-size: 20px;
        margin-top: 2rem;
        background: #4CAF50;
        border: none;
        border-radius: 5px;
        color: white;
        cursor: pointer;
        transition: background 0.3s;
      }

      #xr-button:hover {
        background: #45a049;
      }

      #xr-button:disabled {
        background: #cccccc;
        cursor: not-allowed;
      }

      /* Hide pose and transcription initially */
      #pose, #transcription-log {
        display: none;
      }

      /* Show them only when session is active */
      body.session-active #pose,
      body.session-active #transcription-log {
        display: block;
      }

      #overlay {
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
        background-color: black;
        z-index: -1;  /* Place behind the button and pose text */
      }
      #transcription-log {
        position: fixed;
        bottom: 20px;
        left: 20px;
        right: 20px;
        max-height: 150px;
        overflow-y: auto;
        background: rgba(0, 0, 0, 0.7);
        padding: 10px;
        border-radius: 5px;
        font-size: 16px;
        line-height: 1.4;
        z-index: 1000;
      }
      .log-entry {
        margin: 5px 0;
        border-bottom: 1px solid rgba(255, 255, 255, 0.2);
        padding-bottom: 5px;
      }
      .timestamp {
        color: #888;
        font-size: 0.8em;
        margin-right: 10px;
      }
      
      /* Add connection status indicator styles */
      .connection-status {
        display: inline-block;
        width: 12px;
        height: 12px;
        border-radius: 50%;
        margin-left: auto;
        background: #ccc;
      }
      .connected { background: #4CAF50; }
      .disconnected { background: #f44336; }
      .connecting { 
        background: #ff9800;
        animation: pulse 1.5s infinite;
      }
      @keyframes pulse {
        0% { opacity: 1; }
        50% { opacity: 0.5; }
        100% { opacity: 1; }
      }
    </style>
    <script src="textToSpeech.js"></script>
    <script src="camera.js"></script>
    <script src="audioManager.js"></script>
  </head>
  <body>
    <div id="overlay"></div>
    
    <div class="container">
      <div class="title">Sensor Interface</div>
      <div class="sensor-select">
        <label>
          <input type="checkbox" id="camera-select" checked>
          Front Camera Stream
          <div class="connection-status" id="camera-status"></div>
        </label>
        <label>
          <input type="checkbox" id="pose-select" checked>
          3D Position
          <div class="connection-status" id="pose-status"></div>
        </label>
        <label>
          <input type="checkbox" id="audio-select" checked>
          Microphone
          <div class="connection-status" id="audio-status"></div>
        </label>
        <label>
          <input type="checkbox" id="tts-select" checked>
          Audio
          <div class="connection-status" id="tts-status"></div>
        </label>
      </div>
      <button id="xr-button" disabled>XR not found</button>
    </div>

    <div id="pose">Pose data will appear here.</div>
    <div id="transcription-log"></div>

    <script>
      let xrSession = null;
      let xrRefSpace = null;
      const xrButton = document.getElementById('xr-button');
      const poseDiv = document.getElementById('pose');
      let poseWs = null;  // Separate WebSocket for pose data
      let cameraWs = null;  // Separate WebSocket for camera data
      let tts = null;
      let isSessionActive = false;
      const cameraManager = new CameraManager();
      const audioManager = new AudioManager();
      let audioWs = null;

      // Add sensor selection states
      let enabledSensors = {
        camera: true,
        pose: true,
        audio: true,
        tts: true
      };

      // Add checkbox event listeners
      document.getElementById('camera-select').addEventListener('change', (e) => {
        enabledSensors.camera = e.target.checked;
        if (!e.target.checked && cameraInterval) {
          stopCameraSending();
        } else if (e.target.checked && isSessionActive) {
          startCameraSending();
        }
      });

      document.getElementById('pose-select').addEventListener('change', (e) => {
        enabledSensors.pose = e.target.checked;
        poseDiv.style.display = e.target.checked ? 'block' : 'none';
        checkSupported(); // Recheck AR support when pose tracking is toggled
      });

      document.getElementById('audio-select').addEventListener('change', (e) => {
        enabledSensors.audio = e.target.checked;
        document.getElementById('transcription-log').style.display = e.target.checked ? 'block' : 'none';
        if (!e.target.checked) {
          audioManager.stopAudio();
        } else if (isSessionActive) {
          connectWebSockets();
        }
      });

      // Add TTS checkbox listener
      document.getElementById('tts-select').addEventListener('change', (e) => {
        enabledSensors.tts = e.target.checked;
        if (!e.target.checked && tts) {
          tts.disconnectWebSocket();
          tts = null;
        } else if (e.target.checked && isSessionActive) {
          tts = new TextToSpeech();
          tts.connectWebSocket();
        }
      });

      // Modify checkSupported to only check if position tracking is selected
      function checkSupported() {
        if (!enabledSensors.pose) {
          xrButton.disabled = false;
          xrButton.textContent = 'Start';
          return;
        }

        if (navigator.xr) {
          navigator.xr.isSessionSupported('immersive-ar').then(supported => {
            xrButton.disabled = !supported;
            xrButton.textContent = supported ? 'Start' : 'XR not found';
          });
        } else {
          xrButton.disabled = true;
          xrButton.textContent = 'XR not supported';
        }
      }
      checkSupported();
      navigator.xr && navigator.xr.addEventListener('devicechange', checkSupported);

      // Update the button click handler
      xrButton.addEventListener('click', () => {
        if (!isSessionActive) {
          startSession();
        } else {
          if (xrSession) {
            xrSession.end();
          } else {
            // For non-AR sessions, call onSessionEnded directly
            onSessionEnded();
          }
        }
      });

      // Function to update connection status indicators
      function updateConnectionStatus(type, status) {
        const statusEl = document.getElementById(`${type}-status`);
        if (statusEl) {
          statusEl.className = `connection-status ${status}`;
        }
      }

      // Modify WebSocket connection handlers to update status indicators
      function connectWebSockets() {
        if (!isSessionActive) return;
        
        const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
        const baseUrl = `${protocol}//${window.location.host}`;
        
        if (enabledSensors.pose) {
          updateConnectionStatus('pose', 'connecting');
          // Connect pose WebSocket
          poseWs = new WebSocket(`${baseUrl}/pose`);
          poseWs.onopen = () => {
            console.log('Pose WebSocket connected');
            updateConnectionStatus('pose', 'connected');
          };
          poseWs.onerror = (error) => {
            console.error('Pose WebSocket error:', error);
            updateConnectionStatus('pose', 'disconnected');
          };
          poseWs.onclose = () => {
            updateConnectionStatus('pose', 'disconnected');
            if (isSessionActive) {
              console.log('Pose WebSocket closed, reconnecting...');
              setTimeout(() => {
                if (enabledSensors.pose && isSessionActive) {
                  updateConnectionStatus('pose', 'connecting');
                  connectPoseWebSocket();
                }
              }, 1000);
            }
          };
        }

        if (enabledSensors.camera) {
          updateConnectionStatus('camera', 'connecting');
          // Connect camera WebSocket
          cameraWs = new WebSocket(`${baseUrl}/camera`);
          cameraWs.onopen = () => {
            console.log('Camera WebSocket connected');
            updateConnectionStatus('camera', 'connected');
            if (!cameraInterval && isSessionActive) {
              startCameraSending();
            }
          };
          cameraWs.onerror = (error) => {
            console.error('Camera WebSocket error:', error);
            updateConnectionStatus('camera', 'disconnected');
          };
          cameraWs.onclose = () => {
            updateConnectionStatus('camera', 'disconnected');
            if (isSessionActive) {
              console.log('Camera WebSocket closed, reconnecting...');
              setTimeout(() => {
                if (enabledSensors.camera && isSessionActive) {
                  updateConnectionStatus('camera', 'connecting');
                  connectCameraWebSocket();
                }
              }, 1000);
            }
          };
        }

        if (enabledSensors.audio) {
          updateConnectionStatus('audio', 'connecting');
          audioWs = new WebSocket(`${baseUrl}/audio`);
          audioWs.onopen = () => {
            console.log('Audio WebSocket connected');
            updateConnectionStatus('audio', 'connected');
            audioManager.startAudio(audioWs, isSessionActive);
          };
          audioWs.onerror = (error) => {
            console.error('Audio WebSocket error:', error);
            updateConnectionStatus('audio', 'disconnected');
          };
          audioWs.onclose = () => {
            updateConnectionStatus('audio', 'disconnected');
            if (isSessionActive) {
              console.log('Audio WebSocket closed, reconnecting...');
              setTimeout(() => {
                if (enabledSensors.audio && isSessionActive) {
                  updateConnectionStatus('audio', 'connecting');
                  connectAudioWebSocket();
                }
              }, 1000);
            }
          };
          
          // Add message handler for transcription results
          audioWs.onmessage = (event) => {
            try {
              const data = JSON.parse(event.data);
              if (data.transcription) {
                addTranscriptionEntry(data.transcription);
              }
            } catch (error) {
              console.error('Error parsing audio response:', error);
            }
          };
        }

        // Update TTS status
        if (enabledSensors.tts) {
          updateConnectionStatus('tts', 'connecting');
        }
      }

      function startCameraSending() {
        if (cameraSendingActive) return;
        
        cameraSendingActive = true;
        cameraInterval = setInterval(() => {
          if (cameraWs && cameraWs.readyState === WebSocket.OPEN) {
            const cameraFrame = cameraManager.getLastFrame();
            if (cameraFrame) {
              cameraWs.send(JSON.stringify({
                timestamp: Date.now(),
                camera: cameraFrame,
                width: cameraManager.width || 640,
                height: cameraManager.height || 480
              }));
            }
          }
        }, 30);
      }

      function stopCameraSending() {
        cameraSendingActive = false;
        if (cameraInterval) {
          clearInterval(cameraInterval);
          cameraInterval = null;
        }
      }

      // Modify startSession to handle both AR and non-AR cases
      async function startSession() {
        try {
          if (enabledSensors.pose) {
            // Start AR session only if position tracking is enabled
            xrSession = await navigator.xr.requestSession('immersive-ar', {
              requiredFeatures: ['local'],
              optionalFeatures: ['dom-overlay'],
              domOverlay: { root: document.body },
              environmentBlendMode: 'opaque'
            });
            xrSession.addEventListener('end', onSessionEnded);

            const canvas = document.createElement('canvas');
            const gl = canvas.getContext('webgl', { xrCompatible: true });
            await xrSession.updateRenderState({
              baseLayer: new XRWebGLLayer(xrSession, gl)
            });

            xrRefSpace = await xrSession.requestReferenceSpace('local');
            xrSession.requestAnimationFrame(onXRFrame);
          }

          isSessionActive = true;
          xrButton.textContent = 'Stop';
          
          // Initialize enabled sensors
          if (enabledSensors.tts) {
            tts = new TextToSpeech();
            await tts.connectWebSocket();
          }
          
          connectWebSockets();
          if (enabledSensors.camera) {
            cameraManager.startCamera(cameraWs, isSessionActive);
          }

          document.body.classList.add('session-active');

        } catch (e) {
          console.error('Failed to start session:', e);
          onSessionEnded();  // Clean up if start fails
        }
      }

      // When the session ends, reset button and display
      function onSessionEnded() {
        if (!isSessionActive) return;  // Prevent multiple calls
        console.log('Session ending: Cleaning up resources...');
        
        // Reset all connection statuses
        ['pose', 'camera', 'audio', 'tts'].forEach(type => {
          updateConnectionStatus(type, '');
        });
        
        isSessionActive = false;
        document.body.classList.remove('session-active');
        
        // Clean up WebSockets
        [poseWs, cameraWs, audioWs].forEach(ws => {
          if (ws) {
            ws.close();
          }
        });
        poseWs = cameraWs = audioWs = null;

        // Clean up managers
        cameraManager.stopCamera();
        audioManager.stopAudio();
        if (tts) {
          tts.disconnectWebSocket();
          tts = null;
        }

        // Reset XR session
        if (xrSession) {
          xrSession = null;
          xrRefSpace = null;
        }

        // Update UI
        xrButton.textContent = 'Start';
        poseDiv.textContent = 'Session ended.';
        console.log('Cleanup complete');
      }

      // Modify onXRFrame to only send enabled sensor data
      function onXRFrame(time, frame) {
        xrSession.requestAnimationFrame(onXRFrame);
        const pose = frame.getViewerPose(xrRefSpace);
        if (pose && enabledSensors.pose) {
          const pos = pose.transform.position;
          const o = pose.transform.orientation;
          const text = `Position: ${pos.x.toFixed(3)}, ${pos.y.toFixed(3)}, ${pos.z.toFixed(3)}
            Orientation: ${o.x.toFixed(3)}, ${o.y.toFixed(3)}, ${o.z.toFixed(3)}, ${o.w.toFixed(3)}`;
          // Print on mobile screen
          poseDiv.textContent = text;
          
          // Send pose data via dedicated WebSocket
          if (poseWs && poseWs.readyState === WebSocket.OPEN) {
            const poseData = {
              timestamp: Date.now(),
              pose: {
                position: { x: pos.x, y: pos.y, z: pos.z },
                orientation: { x: o.x, y: o.y, z: o.z, w: o.w }
              }
            };
            poseWs.send(JSON.stringify(poseData));
          }
        } else {
          poseDiv.textContent = 'No pose available.';
        }
      }

      // Add TTS connection status update
      document.getElementById('tts-select').addEventListener('change', (e) => {
        enabledSensors.tts = e.target.checked;
        if (!e.target.checked && tts) {
          tts.disconnectWebSocket();
          tts = null;
          updateConnectionStatus('tts', 'disconnected');
        } else if (e.target.checked && isSessionActive) {
          updateConnectionStatus('tts', 'connecting');
          tts = new TextToSpeech();
          tts.connectWebSocket().then(() => {
            updateConnectionStatus('tts', 'connected');
          }).catch(() => {
            updateConnectionStatus('tts', 'disconnected');
          });
        }
      });

      // Function to add transcription entries to the log
      function addTranscriptionEntry(text) {
        const transcriptionLog = document.getElementById('transcription-log');
        if (!transcriptionLog) return;
        
        const entry = document.createElement('div');
        entry.className = 'log-entry';
        
        const timestamp = document.createElement('span');
        timestamp.className = 'timestamp';
        timestamp.textContent = new Date().toLocaleTimeString();
        
        const content = document.createElement('span');
        content.textContent = text;
        
        entry.appendChild(timestamp);
        entry.appendChild(content);
        transcriptionLog.appendChild(entry);
        
        // Auto-scroll to the latest entry
        transcriptionLog.scrollTop = transcriptionLog.scrollHeight;
        
        // Limit the number of entries to prevent memory issues
        while (transcriptionLog.children.length > 50) {
          transcriptionLog.removeChild(transcriptionLog.firstChild);
        }
      }
    </script>
  </body>
</html>
